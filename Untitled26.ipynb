{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled26.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haiderzm/NeuralNetwithPyTorch/blob/master/Untitled26.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "t6gUcB3HPJqn",
        "colab_type": "code",
        "outputId": "bc7ca731-2f59-43b7-8310-7730df7922ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/60/66415660aa46b23b5e1b72bc762e816736ce8d7260213e22365af51e8f9c/torch-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (591.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 591.8MB 29kB/s \n",
            "tcmalloc: large alloc 1073750016 bytes == 0x60b0a000 @  0x7f8b6484a2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cqxMxRC1Pw9N",
        "colab_type": "code",
        "outputId": "d78395a0-ddee-48d4-953a-18d46f8644c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.nn  as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model (nn.Module):\n",
        "  def __init__(self):\n",
        "    super (). __init__()\n",
        "    \n",
        "    self.fc1=nn.Linear (2,4)\n",
        "    self.out=nn.Linear (4,1)\n",
        "    \n",
        "    \n",
        "  def forward (self,x):\n",
        "    x=F.relu(self.fc1 (x))\n",
        "    x=F.sigmoid (self.out (x))\n",
        "    \n",
        "    return x\n",
        "net = Model ()\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
            "  (out): Linear(in_features=4, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "m-kRGJirRv9t",
        "colab_type": "code",
        "outputId": "8613f1f1-1b7d-419e-83f9-2ef7f6d1fd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4701
        }
      },
      "cell_type": "code",
      "source": [
        "x=torch.tensor ([[0,0],[0,1],[1,0],[1,1]] ,dtype=torch.float32)\n",
        "y=torch.tensor ([[0],[1],[1],[0]],dtype=torch.float32)\n",
        "\n",
        "criterion = nn.MSELoss ()\n",
        "optimizer=torch.optim.Adam (net.parameters (),lr=0.01)\n",
        "\n",
        "for epoch in range (100):\n",
        "  optimizer.zero_grad ()\n",
        "  out=net (x)\n",
        "  loss=criterion (out,y)\n",
        "  loss.backward ()\n",
        "  optimizer.step ()\n",
        "  \n",
        "  print (epoch+1,\" \",loss.item ())\n",
        "  \n",
        "net (x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1   0.24203920364379883\n",
            "2   0.24131612479686737\n",
            "3   0.24062515795230865\n",
            "4   0.23987871408462524\n",
            "5   0.23909464478492737\n",
            "6   0.23829248547554016\n",
            "7   0.2374773621559143\n",
            "8   0.23664134740829468\n",
            "9   0.23577482998371124\n",
            "10   0.2348765879869461\n",
            "11   0.23395149409770966\n",
            "12   0.23300375044345856\n",
            "13   0.2320326268672943\n",
            "14   0.2310335636138916\n",
            "15   0.2300027757883072\n",
            "16   0.22897985577583313\n",
            "17   0.22787226736545563\n",
            "18   0.22677379846572876\n",
            "19   0.22564543783664703\n",
            "20   0.22461634874343872\n",
            "21   0.2235056459903717\n",
            "22   0.2223902940750122\n",
            "23   0.22121727466583252\n",
            "24   0.2200705111026764\n",
            "25   0.21882182359695435\n",
            "26   0.21753638982772827\n",
            "27   0.21624748408794403\n",
            "28   0.21492472290992737\n",
            "29   0.21351642906665802\n",
            "30   0.2122688591480255\n",
            "31   0.21093417704105377\n",
            "32   0.2094794064760208\n",
            "33   0.20800289511680603\n",
            "34   0.20652644336223602\n",
            "35   0.20504772663116455\n",
            "36   0.2035371959209442\n",
            "37   0.20199055969715118\n",
            "38   0.20039676129817963\n",
            "39   0.19876191020011902\n",
            "40   0.19708110392093658\n",
            "41   0.19565603137016296\n",
            "42   0.1942913830280304\n",
            "43   0.19264504313468933\n",
            "44   0.1910329908132553\n",
            "45   0.1894465982913971\n",
            "46   0.1877359300851822\n",
            "47   0.185947984457016\n",
            "48   0.18428100645542145\n",
            "49   0.1826734095811844\n",
            "50   0.1809450089931488\n",
            "51   0.17912918329238892\n",
            "52   0.17741239070892334\n",
            "53   0.1756841540336609\n",
            "54   0.17393988370895386\n",
            "55   0.172003835439682\n",
            "56   0.17026446759700775\n",
            "57   0.16844542324543\n",
            "58   0.16662080585956573\n",
            "59   0.1648937165737152\n",
            "60   0.16306588053703308\n",
            "61   0.161126509308815\n",
            "62   0.15935103595256805\n",
            "63   0.15751463174819946\n",
            "64   0.15568643808364868\n",
            "65   0.15381012856960297\n",
            "66   0.1519593596458435\n",
            "67   0.15000781416893005\n",
            "68   0.14827291667461395\n",
            "69   0.14627937972545624\n",
            "70   0.1445813924074173\n",
            "71   0.1428736001253128\n",
            "72   0.14089252054691315\n",
            "73   0.13892970979213715\n",
            "74   0.1370135098695755\n",
            "75   0.13511843979358673\n",
            "76   0.1333303451538086\n",
            "77   0.13134294748306274\n",
            "78   0.12944447994232178\n",
            "79   0.12759146094322205\n",
            "80   0.1257248967885971\n",
            "81   0.12387172877788544\n",
            "82   0.12201918661594391\n",
            "83   0.12018565088510513\n",
            "84   0.11837513744831085\n",
            "85   0.1166057363152504\n",
            "86   0.11467195302248001\n",
            "87   0.11307093501091003\n",
            "88   0.11131565272808075\n",
            "89   0.10949350148439407\n",
            "90   0.10769826918840408\n",
            "91   0.10592269152402878\n",
            "92   0.10422110557556152\n",
            "93   0.10246279835700989\n",
            "94   0.10076713562011719\n",
            "95   0.09913687407970428\n",
            "96   0.09737277776002884\n",
            "97   0.09574893862009048\n",
            "98   0.09410948306322098\n",
            "99   0.09243252873420715\n",
            "100   0.09084737300872803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2990],\n",
              "        [0.7018],\n",
              "        [0.7008],\n",
              "        [0.2986]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "jyKIRNZwUni2",
        "colab_type": "code",
        "outputId": "ac545991-22bd-498b-889a-33696c06d8dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "cell_type": "code",
      "source": [
        "test=torch. tensor  ([[0,0]],dtype=torch.float32)\n",
        "print (net (test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2990]], grad_fn=<SigmoidBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}